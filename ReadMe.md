# Abstract

A growing literature on inference in Difference-in-differences design has been pessimistic about hypothesis tests of correct size especially with fewer groups. In this paper, we propose and evaluate several methods through Monte Carlo simulations, which are capable of providing correctly sized tests even with a small number of groups. Moreover in this paper, we evaluate the efficacy of these methodologies in detecting genuine effects, which presents a more serious challenge in DD estimation than obtaining a correct test size. Through extensive Monte Carlo simulations, we establish the small sample properties of the estimators and evaluate their performance across a variety of data-generating processes. Furthermore, we apply the findings from our simulations to a real-world dataset, demonstrating the empirical utility of the best-performing estimator we identify.
