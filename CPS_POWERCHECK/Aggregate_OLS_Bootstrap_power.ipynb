{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function is necessary to extract the standard error values from the wildboottest result table\n",
    "\n",
    "def calculate_standard_error(t_statistic, parameter_estimate):\n",
    "    \"\"\"\n",
    "    Calculate the standard error given a t-statistic and the parameter estimate.\n",
    "    \n",
    "    Parameters:\n",
    "    t_statistic (float): The t-statistic value.\n",
    "    parameter_estimate (float): The estimated parameter value (e.g., mean difference).\n",
    "    \n",
    "    Returns:\n",
    "    float: The calculated standard error.\n",
    "    \"\"\"\n",
    "    if t_statistic == 0:\n",
    "        raise ValueError(\"t_statistic cannot be zero.\")\n",
    "    return abs(parameter_estimate / t_statistic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\sneha\\Downloads\\cps_00006.csv.gz'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smp\n",
    "from wildboottest.wildboottest import wildboottest\n",
    "from cps_data_prep import cps_data\n",
    "\n",
    "alpha = 0.05  # Significance level\n",
    "num_simulations = 10\n",
    "\n",
    "\n",
    "reject_count = 0  # Counter for the number of rejections\n",
    "true_beta1_value = 0   # Initialising the counters\n",
    "bias_values = []\n",
    "squared_error_values = []\n",
    "standard_error_values =[]\n",
    "beta1_estimates = []\n",
    "\n",
    "\n",
    "df = cps_data(file_path = file_path)\n",
    "\n",
    "for _ in range(num_simulations):\n",
    "   \n",
    "    data = df.copy()\n",
    "    \n",
    "    states = data['STATEFIP'].unique()\n",
    "    \n",
    "    # Randomly selecting  half of the states to be in the treatment group\n",
    "    \n",
    "    treatment_states = np.random.choice(states, size=len(states)//2, replace=False)\n",
    "\n",
    "    # Assigning treatment year to each treatment state, staggered between 1985 and 1995\n",
    "\n",
    "    treatment_years = np.random.choice(range(1985, 1995), size=len(treatment_states), replace=True)\n",
    "    state_to_treatment_year = dict(zip(treatment_states, treatment_years))\n",
    "\n",
    "    # Adding a treatment column to the DataFrame\n",
    "\n",
    "    data['TREATMENT'] = data.apply(lambda x: 1 if x['STATEFIP'] in treatment_states and x['YEAR'] >= state_to_treatment_year[x['STATEFIP']] else 0, axis=1)\n",
    "\n",
    "    data['outcome'] = data.apply(lambda x: x['INCWAGE']*(1.02) if x['TREATMENT'] == 1 else x['INCWAGE'], axis=1)\n",
    "\n",
    "    data['outcome'] = np.log(data['outcome'])\n",
    "\n",
    "    # Data aggregation is being done after the 2% effect has been introduced\n",
    "\n",
    "    X = data[['High School', \"Master's Degree\", 'AGE']]\n",
    "    y = data['outcome']\n",
    "\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    y_pred = model.predict(X)   # Obtain predicted values from the fitted model\n",
    "\n",
    "    residuals = y - y_pred\n",
    "\n",
    "    data['Residuals'] = residuals\n",
    "\n",
    "    cps_agg = data.groupby(['STATEFIP', 'YEAR'])[['Residuals', 'TREATMENT']].mean().reset_index()\n",
    "\n",
    "    dummy_df_state = pd.get_dummies(cps_agg['STATEFIP'], prefix='STATEFIP', drop_first=True)  # One-hot encode STATEFIP and YEAR\n",
    "    dummy_df_year = pd.get_dummies(cps_agg['YEAR'], prefix='YEAR', drop_first=True)\n",
    "\n",
    "    \n",
    "    cps_agg = pd.concat([cps_agg, dummy_df_state, dummy_df_year], axis=1)\n",
    "\n",
    "    \n",
    "    boolean_columns = ['STATEFIP_2', 'STATEFIP_4', 'STATEFIP_5', 'STATEFIP_6', 'STATEFIP_8', 'STATEFIP_9',   \n",
    "                        'STATEFIP_10', 'STATEFIP_12', 'STATEFIP_13', 'STATEFIP_15', 'STATEFIP_16', 'STATEFIP_17',\n",
    "                        'STATEFIP_18', 'STATEFIP_19', 'STATEFIP_20', 'STATEFIP_21', 'STATEFIP_22', 'STATEFIP_23',\n",
    "                        'STATEFIP_24', 'STATEFIP_25', 'STATEFIP_26', 'STATEFIP_27', 'STATEFIP_28', 'STATEFIP_29',\n",
    "                        'STATEFIP_30', 'STATEFIP_31', 'STATEFIP_32', 'STATEFIP_33', 'STATEFIP_34', 'STATEFIP_35',\n",
    "                        'STATEFIP_36', 'STATEFIP_37', 'STATEFIP_38', 'STATEFIP_39', 'STATEFIP_40', 'STATEFIP_41',\n",
    "                        'STATEFIP_42', 'STATEFIP_44', 'STATEFIP_45', 'STATEFIP_46', 'STATEFIP_47', 'STATEFIP_48',\n",
    "                        'STATEFIP_49', 'STATEFIP_50', 'STATEFIP_51', 'STATEFIP_53', 'STATEFIP_54', 'STATEFIP_55',\n",
    "                        'STATEFIP_56', 'YEAR_1981', 'YEAR_1982', 'YEAR_1983', 'YEAR_1984', 'YEAR_1985', 'YEAR_1986',\n",
    "                        'YEAR_1987', 'YEAR_1988', 'YEAR_1989', 'YEAR_1990', 'YEAR_1991', 'YEAR_1992', 'YEAR_1993',\n",
    "                        'YEAR_1994', 'YEAR_1995', 'YEAR_1996', 'YEAR_1997', 'YEAR_1998', 'YEAR_1999', 'YEAR_2000']   # Convert True and False to 1 and 0 in the specified columns\n",
    "\n",
    "    cps_agg[boolean_columns] = cps_agg[boolean_columns].astype(int)\n",
    "\n",
    "    data = cps_agg.copy()\n",
    "\n",
    "    model = smp.ols(formula = \"Residuals ~ TREATMENT + STATEFIP_2 + STATEFIP_4 + STATEFIP_5 + STATEFIP_6 + STATEFIP_8 + STATEFIP_9 + STATEFIP_10 + STATEFIP_12 + STATEFIP_13 + STATEFIP_15 + STATEFIP_16 + STATEFIP_17 + STATEFIP_18 + STATEFIP_19 + STATEFIP_20 + STATEFIP_21 + STATEFIP_22 + STATEFIP_23 + STATEFIP_24 + STATEFIP_25 + STATEFIP_26 + STATEFIP_27 + STATEFIP_28 + STATEFIP_29 + STATEFIP_30 + STATEFIP_31 + STATEFIP_32 + STATEFIP_33 + STATEFIP_34 + STATEFIP_35 + STATEFIP_36 + STATEFIP_37 + STATEFIP_38 + STATEFIP_39 + STATEFIP_40 + STATEFIP_41 + STATEFIP_42 + STATEFIP_44 + STATEFIP_45 + STATEFIP_46 + STATEFIP_47 + STATEFIP_48 + STATEFIP_49 + STATEFIP_50 + STATEFIP_51 + STATEFIP_53 + STATEFIP_54 + STATEFIP_55 + STATEFIP_56 + YEAR_1981 + YEAR_1982 + YEAR_1983 + YEAR_1984 + YEAR_1985 + YEAR_1986 + YEAR_1987 + YEAR_1988 + YEAR_1989 + YEAR_1990 + YEAR_1991 + YEAR_1992 + YEAR_1993 + YEAR_1994 + YEAR_1995 + YEAR_1996 + YEAR_1997 + YEAR_1998 + YEAR_1999 + YEAR_2000\" , data = data)\n",
    "\n",
    "    result = model.fit()\n",
    "    wildboottest_results = wildboottest(model, param=\"TREATMENT\", cluster=data['STATEFIP'], B= 400, bootstrap_type='11', show = False)\n",
    "    wildboottest_results = pd.DataFrame(wildboottest_results)\n",
    "    p_value = wildboottest_results['p-value'].iloc[0]\n",
    "    param = result.params['TREATMENT']\n",
    "    t_stat = wildboottest_results['statistic'].iloc[0] \n",
    "\n",
    "\n",
    "    # Checking  if null hypothesis for beta1 is rejected\n",
    "\n",
    "    if p_value < alpha:\n",
    "        reject_count += 1\n",
    "\n",
    "    beta1_estimates.append(param)\n",
    "\n",
    "    bias = np.mean(beta1_estimates) - true_beta1_value\n",
    "\n",
    "    squared_error = (param - true_beta1_value) ** 2\n",
    "    squared_error_values.append(squared_error)\n",
    "\n",
    "    # Extracting the standard error of the 'TREATMENT' coefficient \n",
    "\n",
    "    standard_error = calculate_standard_error(t_stat, param)\n",
    "    standard_error_values.append(standard_error)\n",
    "\n",
    "\n",
    "type1_error = reject_count/ num_simulations\n",
    "bias = np.mean(bias)\n",
    "mse = np.mean(squared_error_values)\n",
    "rmse = np.sqrt(mse)\n",
    "average_standard_error = np.mean(standard_error_values)\n",
    "\n",
    "\n",
    "std_error_beta_distribution = np.std(beta1_estimates)  # Calculating the standard error of the distribution of beta\n",
    "\n",
    "confidence_interval = (\n",
    "    np.mean(beta1_estimates) - 1.96 * std_error_beta_distribution,\n",
    "    np.mean(beta1_estimates) + 1.96 * std_error_beta_distribution\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Number of times null hypothesis is rejected: {reject_count} out of {num_simulations} simulations\")\n",
    "print(f\"Type 1 Error: {type1_error}\")\n",
    "print(f\"Bias for Coefficient of Treatment : {bias}\")\n",
    "print(f\"MSE for Coefficient of Treatment : {mse}\")\n",
    "print(f\"RMSE for Coefficient of Treatment : {mse}\")\n",
    "print(f\"Average Standard Error: {average_standard_error}\")\n",
    "print(f\"Standard Error of the beta_1 distribution: {std_error_beta_distribution}\")\n",
    "print(f'The confidence interval is {confidence_interval[0] , {confidence_interval[1]}}')\n",
    "\n",
    "sns.kdeplot(beta1_estimates, bw_adjust=0.5, fill=True)\n",
    "plt.xlabel(r'$\\beta_1$ Estimates')  # Using LaTeX for beta_1\n",
    "plt.ylabel('Density')\n",
    "plt.title(r'Distribution of $\\beta_1$ Estimates')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
