{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50   # can be changed accordingly to the desired number of states\n",
    "\n",
    "T = 20  # time periods is kept to be 20 for all our analysis\n",
    "\n",
    "rho = 0.8 # can be changed accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation code\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_staggered_law_ar1_data(N, T, rho, num_individuals, mean=0, std_dev=1):\n",
    "    \n",
    "    white_noise = np.random.normal(mean, std_dev, size=(N, num_individuals, T)) # generatingk random white noise for each individual\n",
    "\n",
    "    data = np.zeros((N, num_individuals, T))  # Initializing the array to store the data\n",
    "\n",
    "    # Including state and time effects \n",
    "\n",
    "    alphas = np.random.normal(0,1, size=N)\n",
    "    betas = np.random.normal(0,1, size = T)\n",
    "\n",
    "    # Generating the AR(1) process data for each individual\n",
    "\n",
    "    for i in range(N):\n",
    "        alpha = alphas[i]\n",
    "        for j in range(num_individuals):\n",
    "            for t in range(T):\n",
    "                beta = betas[t]\n",
    "                if t == 0:\n",
    "                    data[i, j, t] = alpha + beta + white_noise[i, j, t]\n",
    "                else:\n",
    "                    data[i, j, t] = alpha + beta + rho * data[i, j, t - 1] + white_noise[i, j, t]\n",
    "\n",
    "    \n",
    "    reshaped_data = data.reshape((N * num_individuals, T))  # Reshaping the data array for easier DataFrame creation\n",
    "\n",
    " \n",
    "    df = pd.DataFrame(reshaped_data, columns=[f'{t}' for t in range(T)])    # Creating a DataFrame with column names as time periods\n",
    "\n",
    "    \n",
    "    df['state'] = np.repeat(np.arange(1, N + 1), num_individuals)  # Add a new 'state' column with repeated state values\n",
    "\n",
    "    \n",
    "    df['individual'] = np.tile(np.arange(1, num_individuals + 1), N)  # Add a new 'individual' column with repeated individual values\n",
    "\n",
    "\n",
    "    melted_df = pd.melt(df, id_vars=['state', 'individual'], var_name='time', value_name= 'value') # to take the data in the long format\n",
    "\n",
    "   \n",
    "    melted_df['time'] = melted_df['time'].astype(int)   # Converting the 'time' column to int\n",
    "\n",
    "\n",
    "    data = melted_df.copy()\n",
    "\n",
    "    data['time'] = data['time'].astype(int)\n",
    "\n",
    "   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "alpha = 0.05  # Significance level\n",
    "num_simulations = 5000\n",
    "num_individuals = 1\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "reject_count = 0  # Counter for the number of rejections\n",
    "true_beta1_value = 0   # Initialising the counters\n",
    "bias_values = []\n",
    "squared_error_values = []\n",
    "standard_error_values =[]\n",
    "beta1_estimates = []\n",
    "\n",
    "for _ in range(num_simulations):\n",
    "\n",
    "    data = generate_staggered_law_ar1_data( N, T, rho, num_individuals) # this time the data generation is inside the loop to ensure everytime new data is generated\n",
    "\n",
    "    states = data['state'].unique()\n",
    "    \n",
    "    treatment_states = np.random.choice(states, size=len(states)//2, replace=False)   # To give the treatment to exactly half the states in a staggered approach\n",
    "\n",
    "    treatment_years = np.random.choice(range(5, 15), size=len(treatment_states), replace=True)  # Assigning treatment year to each treatment state, staggered between 5 and 15th time period\n",
    "\n",
    "    state_to_treatment_year = dict(zip(treatment_states, treatment_years))\n",
    "\n",
    "    # Adding a treatment column to the DataFrame\n",
    "    \n",
    "    data['TREATMENT'] = data.apply(lambda x: 1 if x['state'] in treatment_states and x['time'] >= state_to_treatment_year[x['state']] else 0, axis=1)\n",
    "\n",
    "    data['time'] = data['time'].astype(int)\n",
    "\n",
    "    state_dummies = pd.get_dummies(data['state'], prefix='state', drop_first = True)  # Create state dummy variables\n",
    "\n",
    "    state_dummies = state_dummies.astype(int)\n",
    "\n",
    "    time_dummies = pd.get_dummies(data['time'].astype(int), prefix='time', drop_first = True) # Create time dummy variables\n",
    "\n",
    "    time_dummies = time_dummies.astype(int)\n",
    "\n",
    "    data = pd.concat([data, state_dummies, time_dummies], axis=1)\n",
    "\n",
    "    columns_to_exclude = ['state', 'value', 'individual', 'time']\n",
    "\n",
    "    X_columns = [col for col in data.columns if col not in columns_to_exclude]\n",
    "\n",
    "    X = data[X_columns]\n",
    "    X = sm.add_constant(X)\n",
    "    Y = data['value'] \n",
    "    model = sm.OLS(Y, X).fit(cov_type='cluster', use_t = True, cov_kwds={'groups': data['state'].astype(str)})\n",
    "\n",
    "    bias_value = model.params['TREATMENT'] - true_beta1_value\n",
    "    \n",
    "    bias_values.append(bias_value)\n",
    "\n",
    "    squared_error = (model.params['TREATMENT'] - true_beta1_value) ** 2\n",
    "    squared_error_values.append(squared_error)\n",
    "    \n",
    "    standard_error = model.bse['TREATMENT']\n",
    "    standard_error_values.append(standard_error)\n",
    "\n",
    "    beta1_estimates.append(model.params['TREATMENT'])\n",
    "    \n",
    "    \n",
    "    # Checking  if null hypothesis for beta1 is rejected\n",
    "\n",
    "    if model.pvalues['TREATMENT'] < alpha:\n",
    "        reject_count += 1\n",
    "\n",
    "\n",
    "type1_error = reject_count / num_simulations\n",
    "\n",
    "bias = np.mean(bias_values)\n",
    "mse = np.mean(squared_error)   \n",
    "rmse = np.sqrt(mse)  \n",
    "average_standard_error = np.mean(standard_error_values)   \n",
    "std_error_beta_distribution = np.std(beta1_estimates)\n",
    "\n",
    "confidence_interval = (\n",
    "    np.mean(beta1_estimates) - 1.96 * std_error_beta_distribution,\n",
    "    np.mean(beta1_estimates) + 1.96 * std_error_beta_distribution\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Number of times null hypothesis is rejected for rho {rho}: {reject_count} out of {num_simulations} simulations\")\n",
    "print(f\"Type 1 Error: {type1_error}\")\n",
    "print(f\"Bias for Coefficient of Treatment : {bias}\")\n",
    "print(f\"MSE for Coefficient of Treatment : {mse}\")\n",
    "print(f\"RMSE for Coefficient of Treatment : {rmse}\")\n",
    "print(f\"Average Standard Error: {average_standard_error}\")\n",
    "print(f\"Standard Error of the beta_1 distribution: {std_error_beta_distribution}\")\n",
    "print(f'The confidence interval is {confidence_interval[0] , {confidence_interval[1]}}')\n",
    "\n",
    "sns.histplot(beta1_estimates, kde = True)\n",
    "plt.xlabel(r'$\\beta_1$ Estimates')  # Using LaTeX for beta_1\n",
    "plt.ylabel('Density')\n",
    "plt.title(r'Distribution of $\\beta_1$ Estimates')\n",
    "\n",
    "\n",
    "mean_beta1_estimate = np.mean(beta1_estimates) # Calculating mean of beta1 estimates for marking on plot\n",
    "\n",
    "# Adding vertical lines for the confidence interval and the mean beta1 estimate\n",
    "\n",
    "plt.axvline(x=confidence_interval[0], color='red', linestyle='--', label='Lower CI')\n",
    "plt.axvline(x=confidence_interval[1], color='green', linestyle='--', label='Upper CI')\n",
    "plt.axvline(x=mean_beta1_estimate, color='blue', linestyle='-', label='Mean Beta1 Estimate')\n",
    "\n",
    "plt.legend(loc='lower left', bbox_to_anchor=(1, 0))\n",
    "\n",
    "plt.grid(True, which='both', linestyle='-', linewidth=0.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
