{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\sneha\\Downloads\\cps_00006.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "# data preperation code\n",
    "\n",
    "\n",
    "def cps_data(file_path):\n",
    "  \n",
    "    df = pd.read_csv(file_path, compression='gzip', header=0) # importing the data\n",
    "\n",
    "    \n",
    "    df = df[(df['INCWAGE'] != 99999999) & (df['INCWAGE'] != 0) & (df['INCWAGE'] != 999)]  # dropping the rows containing invalid and 0 INCWAGE according to the labels\n",
    "\n",
    "    df['INCWAGE'] = np.log(df['INCWAGE'])  # taking log of weekly earnings which will be our dependent variable in the regressions\n",
    "\n",
    "\n",
    "    df = df[(df['EDUC'] != 0) & (df['EDUC'] != 1)]  # dropping education levels 0 and 1 as they are invalid entries as per the labels of the dataset\n",
    "\n",
    "    df = df[(df['YEAR'] >= 1980) & (df['YEAR'] <= 2000)]  # taking the time frame from 1980 to 2000\n",
    "\n",
    "    def categorize_education(educ_code): # creating a fucntion to categorize education levels\n",
    "        if educ_code <= 10:\n",
    "            return 'Up to Grade 10'\n",
    "        elif 10 < educ_code <= 70:\n",
    "            return 'High School'\n",
    "        elif 70 < educ_code <= 123:\n",
    "            return \"Master's Degree\"\n",
    "        else:\n",
    "            return 'Doctorate Degree'\n",
    "\n",
    "    \n",
    "    df['Education_Category'] = df['EDUC'].apply(categorize_education) # applying the function to create a new 'Education_Category' column\n",
    "\n",
    "    df = pd.get_dummies(df, columns=['Education_Category'], prefix='', prefix_sep='', drop_first=True)\n",
    "\n",
    "    boolean = ['Up to Grade 10', 'High School', \"Master's Degree\"]\n",
    "    df[boolean] = df[boolean].astype(int)\n",
    "\n",
    "    df = df[~((df['STATEFIP'] > 56) | (df['STATEFIP'] == 11))]  # taking only the 50 states of the States and exclusing the regions as per the labels of the dataset\n",
    "\n",
    "    df = df[(df['AGE'] >= 25) & (df['AGE'] <= 50)]  # taking the age group from 25 to 50\n",
    "\n",
    "    df = df[df['SEX'] == 2] # taking only female respondents\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# data aggregation code\n",
    "\n",
    "def process_cps_data(file_path):\n",
    "\n",
    "    df = cps_data(file_path)\n",
    "\n",
    "    X = df[['High School', \"Master's Degree\", 'Up to Grade 10', 'AGE']] # the covariates used 1st stage of data aggregation\n",
    "    y = df['INCWAGE']\n",
    "\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    y_pred = model.predict(X)  # obtaining the predicted values of the model\n",
    "\n",
    "    residuals = y - y_pred\n",
    "\n",
    "    df['Residuals'] = residuals\n",
    "\n",
    "    residuals_mean_by_state_year = df.groupby(['STATEFIP', 'YEAR'])['Residuals'].mean().reset_index()\n",
    "\n",
    "    residuals_mean_by_state_year \n",
    "\n",
    "    return residuals_mean_by_state_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Resid   R-squared:                       0.146\n",
      "Model:                            OLS   Adj. R-squared:                  0.143\n",
      "Method:                 Least Squares   F-statistic:                     51.02\n",
      "Date:                Thu, 22 Feb 2024   Prob (F-statistic):           1.90e-30\n",
      "Time:                        22:21:27   Log-Likelihood:                 1145.6\n",
      "No. Observations:                 900   AIC:                            -2283.\n",
      "Df Residuals:                     896   BIC:                            -2264.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -2.157e-15      0.002  -9.53e-13      1.000      -0.004       0.004\n",
      "Resid_lag1     0.3470      0.033     10.465      0.000       0.282       0.412\n",
      "Resid_lag2     0.0008      0.034      0.023      0.982      -0.066       0.068\n",
      "Resid_lag3     0.1064      0.032      3.284      0.001       0.043       0.170\n",
      "==============================================================================\n",
      "Omnibus:                        2.995   Durbin-Watson:                   2.055\n",
      "Prob(Omnibus):                  0.224   Jarque-Bera (JB):                3.182\n",
      "Skew:                          -0.048   Prob(JB):                        0.204\n",
      "Kurtosis:                       3.275   Cond. No.                         17.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# wage correlogram regression\n",
    "\n",
    "\n",
    "data = process_cps_data(file_path)  # importing the processed and aggregated data\n",
    "\n",
    " \n",
    "dummy_df = pd.get_dummies(data['STATEFIP'], prefix='STATEFIP', drop_first=True).astype(int)\n",
    "\n",
    "    \n",
    "data = pd.concat([data, dummy_df], axis=1)   # Concatenate the dummy variables with the original DataFrame\n",
    "\n",
    "dummy_df2 = pd.get_dummies(data['YEAR'], prefix='YEAR', drop_first=True).astype(int)\n",
    "\n",
    "    \n",
    "data = pd.concat([data, dummy_df2], axis=1)   # Concatenate the dummy variables with the original DataFrame\n",
    "\n",
    "X = data[['STATEFIP_2', 'STATEFIP_4',\n",
    "       'STATEFIP_5', 'STATEFIP_6', 'STATEFIP_8', 'STATEFIP_9', 'STATEFIP_10',\n",
    "       'STATEFIP_12', 'STATEFIP_13', 'STATEFIP_15', 'STATEFIP_16',\n",
    "       'STATEFIP_17', 'STATEFIP_18', 'STATEFIP_19', 'STATEFIP_20',\n",
    "       'STATEFIP_21', 'STATEFIP_22', 'STATEFIP_23', 'STATEFIP_24',\n",
    "       'STATEFIP_25', 'STATEFIP_26', 'STATEFIP_27', 'STATEFIP_28',\n",
    "       'STATEFIP_29', 'STATEFIP_30', 'STATEFIP_31', 'STATEFIP_32',\n",
    "       'STATEFIP_33', 'STATEFIP_34', 'STATEFIP_35', 'STATEFIP_36',\n",
    "       'STATEFIP_37', 'STATEFIP_38', 'STATEFIP_39', 'STATEFIP_40',\n",
    "       'STATEFIP_41', 'STATEFIP_42', 'STATEFIP_44', 'STATEFIP_45',\n",
    "       'STATEFIP_46', 'STATEFIP_47', 'STATEFIP_48', 'STATEFIP_49',\n",
    "       'STATEFIP_50', 'STATEFIP_51', 'STATEFIP_53', 'STATEFIP_54',\n",
    "       'STATEFIP_55', 'STATEFIP_56', 'YEAR_1981', 'YEAR_1982', 'YEAR_1983',\n",
    "       'YEAR_1984', 'YEAR_1985', 'YEAR_1986', 'YEAR_1987', 'YEAR_1988',\n",
    "       'YEAR_1989', 'YEAR_1990', 'YEAR_1991', 'YEAR_1992', 'YEAR_1993',\n",
    "       'YEAR_1994', 'YEAR_1995', 'YEAR_1996', 'YEAR_1997', 'YEAR_1998',\n",
    "       'YEAR_1999', 'YEAR_2000']]\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "Y = data['Residuals'] \n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "data['Resid'] = model.resid\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "df['Resid_lag1'] = df.groupby('STATEFIP')['Resid'].shift(1)  # getting the lagged value of the residuals\n",
    "df['Resid_lag2'] = df.groupby('STATEFIP')['Resid'].shift(2)\n",
    "df['Resid_lag3'] = df.groupby('STATEFIP')['Resid'].shift(3)\n",
    "\n",
    "\n",
    "df.dropna(inplace=True)   # Drop rows with NaN values (due to shifting)\n",
    "\n",
    "X = df[['Resid_lag1', 'Resid_lag2', 'Resid_lag3']]    \n",
    "y = df['Resid']  \n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
